learning_rate : 0.001
activation_func : relu
optimiser : batch
epochs : 100
batch_size : 20
layers : [11, 15, 15, 10]
accuracy : 5.848
precision : 2.686
recall : 6.129
f1 : 3.718
