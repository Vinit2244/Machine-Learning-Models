learning_rate : 0.01
activation_func : relu
optimiser : batch
epochs : 100
batch_size : 20
layers : [11, 15, 15, 10]
accuracy : 5.848
precision : 10.42
recall : 12.196
f1 : 10.905
